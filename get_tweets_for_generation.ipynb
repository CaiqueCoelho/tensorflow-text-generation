{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Top arrobas +\n",
    "# 2. Primeiro tweet do Ano, data e texto e Ultimo tweet +\n",
    "# 3. Dias com mais tweets +\n",
    "# 4. Total de tweets no ano +\n",
    "# 5. Palavras mais usadas \n",
    "# 6. Pessoas mais curtidas + \n",
    "# 7. Dia que deu mais likes +\n",
    "# 8. Total de curtidas no ano \n",
    "# 8. Pessoas que mais foram retweetadas +\n",
    "# 9. Dia com mais retweets +\n",
    "# 10. Tweet com mais likes *\n",
    "# 11. Tweet com mais coment√°rios *\n",
    "# 12. Tweet com mais retweets *\n",
    "# 13. Recebeu quantos likes?\n",
    "# 14. Reebeu quantos coment√°rios\n",
    "# 15. Recebeu quantos retweets?\n",
    "# 16. Palavras usadas quantidade?\n",
    "# 17. Palavras √∫nicas usadas?\n",
    "# 18 Quantida coment√°rios, likes e retweets?\n",
    "# Se usu√°rio tem mais tweets no ano preciso pegar de onde parei *\n",
    "# https://github.com/twintproject/twint\n",
    "# https://github.com/taspinar/twitterscraper\n",
    "\n",
    "stop_words = {\"de\",\"a\",\"o\",\"que\",\"e\",\"do\",\"da\", \"das\", \"em\",\"um\",\"para\",\"√©\",\"com\",\"n√£o\",\"uma\",\"os\",\"no\",\"se\",\"na\",\"por\",\"mais\",\"as\",\"dos\",\n",
    "\"como\",\"mas\",\"foi\",\"ao\",\"ele\",\"das\",\"tem\",\"√†\",\"seu\",\"sua\",\"ou\",\"ser\",\"quando\",\"muito\",\"h√°\",\"nos\",\"j√°\",\"est√°\",\"eu\",\"tamb√©m\",\"s√≥\",\"pelo\",\n",
    "\"pela\",\"at√©\",\"isso\",\"ela\",\"entre\",\"era\",\"depois\",\"sem\",\"mesmo\",\"aos\",\"ter\",\"seus\",\"quem\",\"nas\",\"me\",\"esse\",\"eles\",\"est√£o\",\"voc√™\",\"tinha\",\n",
    "\"foram\",\"essa\",\"num\",\"nem\",\"suas\",\"meu\",\"√†s\",\"minha\",\"t√™m\",\"numa\",\"pelos\",\"elas\",\"havia\",\"seja\",\"qual\",\"ser√°\",\"n√≥s\",\"tenho\",\"lhe\",\"deles\",\n",
    "\"essas\",\"esses\",\"pelas\",\"este\",\"fosse\",\"dele\",\"tu\",\"te\",\"voc√™s\",\"vos\",\"lhes\",\"meus\",\"minhas\",\"teu\",\"tua\",\"teus\",\"tuas\",\"nosso\",\"nossa\",\n",
    "\"nossos\",\"nossas\",\"dela\",\"delas\",\"esta\",\"estes\",\"estas\",\"aquele\",\"aquela\",\"aqueles\",\"aquelas\",\"isto\",\"aquilo\",\"estou\",\"est√°\",\"estamos\",\n",
    "\"est√£o\",\"estive\",\"esteve\",\"estivemos\",\"estiveram\",\"estava\",\"est√°vamos\",\"estavam\",\"estivera\",\"estiv√©ramos\",\"esteja\",\"estejamos\",\"estejam\",\n",
    "\"estivesse\",\"estiv√©ssemos\",\"estivessem\",\"estiver\",\"estivermos\",\"estiverem\",\"hei\",\"h√°\",\"havemos\",\"h√£o\",\"houve\",\"houvemos\",\"houveram\",\n",
    "\"houvera\",\"houv√©ramos\",\"haja\",\"hajamos\",\"hajam\",\"houvesse\",\"houv√©ssemos\", \"haveria\", \"houvessem\",\"houver\",\"houvermos\",\"houverem\",\"houverei\",\"houver√°\",\n",
    "\"houveremos\",\"houver√£o\",\"houveria\",\"houver√≠amos\",\"houveriam\",\"sou\",\"somos\",\"s√£o\",\"era\",\"√©ramos\",\"eram\",\"fui\",\"foi\",\"fomos\",\"foram\",\"fora\",\n",
    "\"f√¥ramos\",\"seja\",\"sejamos\",\"sejam\",\"fosse\",\"f√¥ssemos\",\"fossem\",\"for\",\"formos\",\"forem\",\"serei\",\"ser√°\",\"seremos\",\"ser√£o\",\"seria\",\"ser√≠amos\",\n",
    "\"seriam\",\"tenho\",\"tem\",\"temos\",\"t√©m\",\"tinha\",\"t√≠nhamos\",\"tinham\",\"tive\",\"teve\",\"tivemos\",\"tiveram\",\"tivera\",\"tiv√©ramos\",\"tenha\",\"tenhamos\",\n",
    "\"tenham\",\"tivesse\",\"tiv√©ssemos\",\"tivessem\",\"tiver\",\"tivermos\",\"tiverem\",\"terei\",\"ter√°\",\"teremos\",\"ter√£o\",\"teria\",\"ter√≠amos\",\"teriam\", \"vai\",\n",
    "\"vou\", \"t√£o\", \"alguma\", \"interesse\", \"ter\", \"caso\", \"abaixo\", \"animais\", \"ainda\", \"outras\", \"etc.\", \"em\", \"a\", \"b\", \"c\", \n",
    "\"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"x\", \"y\", \"z\", \".\", \",\", \"-\", \"#\", \"nada\", \"nessa\", \"ano\", \n",
    "\"aqui\", \"tava\", \"ver\", \"todo\",\"antes\", \"pq\", \"a√≠\", \"fazer\", \".\", \"<\", \">\",\n",
    "\"ta\", \"semana\", \"vc\", \"coisa\", \"1\", \"?\", \"to\", \"queria\", \"2\", \"ontem\", \"t√¥\", \"vi\",\n",
    "\"sempre\", \"sendo\", \"quero\", \"bem\", \"coisas\", \"dias\", \"bom\", \"nunca\", \"vcs\", \"pessoas\", \"m√™s\", \"pode\", \"3\", \"pro\", \"faz\", \"olha\",\n",
    "\"nao\", \"menos\", \"l√°\", \"assim\", \"melhor\", \"sabe\", \"!\", \"fazendo\", \"vamos\", \"hj\", \"dessa\", \n",
    "\"boa\", \"ai\", \"fica\", \"dar\", \"quer\", \"porque\", \"sei\", \"vendo\", \"algu√©m\", \"d√°\", \"sobre\", \"onde\", \"verdade\", \"√∫nica\", \"come√ßou\", \"dizer\", \n",
    "\"apenas\", \"ficar\", \"uns\", \"v√£o\", \"acho\", \"kkkk\", \"vez\", \"desde\", \"kkk\", \"algo\", \"normal\", \"dois\", \"atr√°s\", \n",
    "\"pois\", \"10\", \"desse\", \"...\", \"6\", \"nesse\", \"duas\", \"alguns\", \"algumas\", \"ia\", \"fazem\",\n",
    "\"a\", \"agora\", \"ainda\", \"algu√©m\", \"algum\", \"alguma\", \"algumas\", \"alguns\", \"ampla\", \"amplas\", \"amplo\", \"amplos\", \"ante\", \"antes\", \"ao\", \"aos\", \"ap√≥s\", \"aquela\", \"aquelas\", \"aquele\", \"aqueles\", \"aquilo\", \"as\", \"at√©\", \"atrav√©s\", \"cada\", \"coisa\", \"coisas\", \"com\", \"como\", \"contra\", \"contudo\", \"da\", \"daquele\", \"daqueles\", \"das\", \"de\", \"dela\", \"delas\", \"dele\", \"deles\", \"depois\", \"dessa\", \"dessas\", \"desse\", \"desses\", \"desta\", \"destas\", \"deste\", \"deste\", \"destes\", \"deve\", \"devem\", \"devendo\", \"dever\", \"dever√°\", \"dever√£o\", \"deveria\", \"deveriam\", \"devia\", \"deviam\", \"disse\", \"disso\", \"disto\", \"dito\", \"diz\", \"dizem\", \"do\", \"dos\", \"e\", \"√©\", \"ela\", \"elas\", \"ele\", \"eles\", \"em\", \"enquanto\", \"entre\", \"era\", \"essa\", \"essas\", \"esse\", \"esses\", \"esta\", \"est√°\", \"estamos\", \"est√£o\", \"estas\", \"estava\", \"estavam\", \"est√°vamos\", \"este\", \"estes\", \"estou\", \"eu\", \"fazendo\", \"fazer\", \"feita\", \"feitas\", \"feito\", \"feitos\", \"foi\", \"for\", \"foram\", \"fosse\", \"fossem\", \"grande\", \"grandes\", \"h√°\", \"isso\", \"isto\", \"j√°\", \"la\", \"l√°\", \"lhe\", \"lhes\", \"lo\", \"mas\", \"me\", \"mesma\", \"mesmas\", \"mesmo\", \"mesmos\", \"meu\", \"meus\", \"minha\", \"minhas\", \"muita\", \"muitas\", \"muito\", \"muitos\", \"na\", \"n√£o\", \"nas\", \"nem\", \"nenhum\", \"nessa\", \"nessas\", \"nesta\", \"nestas\", \"ningu√©m\", \"no\", \"nos\", \"n√≥s\", \"nossa\", \"nossas\", \"nosso\", \"nossos\", \"num\", \"numa\", \"nunca\", \"o\", \"os\", \"ou\", \"outra\", \"outras\", \"outro\", \"outros\", \"para\", \"pela\", \"pelas\", \"pelo\", \"pelos\", \"pequena\", \"pequenas\", \"pequeno\", \"pequenos\", \"per\", \"perante\", \"pode\", \"pude\", \"podendo\", \"poder\", \"poderia\", \"poderiam\", \"podia\", \"podiam\", \"pois\", \"por\", \"por√©m\", \"porque\", \"posso\", \"pouca\", \"poucas\", \"pouco\", \"poucos\", \"primeiro\", \"primeiros\", \"pr√≥pria\", \"pr√≥prias\", \"pr√≥prio\", \"pr√≥prios\", \"quais\", \"qual\", \"quando\", \"quanto\", \"quantos\", \"que\", \"quem\", \"s√£o\", \"se\", \"seja\", \"sejam\", \"sem\", \"sempre\", \"sendo\", \"ser√°\", \"ser√£o\", \"seu\", \"seus\", \"si\", \"sido\", \"s√≥\", \"sob\", \"sobre\", \"sua\", \"suas\", \"talvez\", \"tamb√©m\", \"tampouco\", \"te\", \"tem\", \"tendo\", \"tenha\", \"ter\", \"teu\", \"teus\", \"ti\", \"tido\", \"tinha\", \"tinham\", \"toda\", \"todas\", \"todavia\", \"todo\", \"todos\", \"tu\", \"tua\", \"tuas\", \"tudo\", \"√∫ltima\", \"√∫ltimas\", \"√∫ltimo\", \"√∫ltimos\", \"um\", \"uma\", \"umas\", \"uns\", \"vendo\", \"ver\", \"vez\", \"vindo\", \"vir\", \"vos\", \"v√≥s\", \n",
    "\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\", \"pra\", '', \"t√°\",  \"dia\", \"hahahaha\", \"hahahahahaha\", \"hahahahaha\", \"haha\", \"hahaha\", \"rsrs\", \"kkkkk\", \"uahsuahsauhsuahs\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now = 2021-06-13 18:56:29.602846\n",
      "date and time = 13/06/2021 18:56:29\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    " \n",
    "print(\"now =\", now)\n",
    "\n",
    "# dd/mm/YY H:M:S\n",
    "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "print(\"date and time =\", dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jwt\n",
    "\n",
    "def getIdFromToken(token):\n",
    "    decoded = jwt.decode(token, verify=False)\n",
    "    idToken = decoded['firebase']['identities']['twitter.com'][0]\n",
    "    return idToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idFromToken = getIdFromToken(\"eyJhbGciOiJSUzI1NiIsImtpZCI6IjNjYmM4ZjIyMDJmNjZkMWIxZTEwMTY1OTFhZTIxNTZiZTM5NWM2ZDciLCJ0eXAiOiJKV1QifQ.eyJuYW1lIjoiQ2HDrXF1ZSBDb2VsaG8iLCJwaWN0dXJlIjoiaHR0cHM6Ly9wYnMudHdpbWcuY29tL3Byb2ZpbGVfaW1hZ2VzLzExNTkzNTE0NDAwNjM4MzIwNzEvX3kzdmdiNlBfbm9ybWFsLmpwZyIsImlzcyI6Imh0dHBzOi8vc2VjdXJldG9rZW4uZ29vZ2xlLmNvbS9yZXRyb3NwZWN0aXZlLXR3aXR0ZXIiLCJhdWQiOiJyZXRyb3NwZWN0aXZlLXR3aXR0ZXIiLCJhdXRoX3RpbWUiOjE2MDg4ODAwMjIsInVzZXJfaWQiOiJTcHE4bXFPY0xJV2VTWXFaeVNEUmxWeFdvNmIyIiwic3ViIjoiU3BxOG1xT2NMSVdlU1lxWnlTRFJsVnhXbzZiMiIsImlhdCI6MTYwODkyMTU5MywiZXhwIjoxNjA4OTI1MTkzLCJlbWFpbCI6ImNhaXF1ZWRwZmNAZ21haWwuY29tIiwiZW1haWxfdmVyaWZpZWQiOmZhbHNlLCJmaXJlYmFzZSI6eyJpZGVudGl0aWVzIjp7InR3aXR0ZXIuY29tIjpbIjIyMjAxNDU3MjIiXSwiZW1haWwiOlsiY2FpcXVlZHBmY0BnbWFpbC5jb20iXX0sInNpZ25faW5fcHJvdmlkZXIiOiJ0d2l0dGVyLmNvbSJ9fQ.hD9P6xfd3PzIfnC14jSs_sQyGqhQ4ssr8jL7U-Em0PfnhkQkDiVl08kezcOPhfs1yX2dRsSkOw1dQ2E2R2fptU2UsvDCwLKqKX9Zm3d0FUZwtVvx4R2OIuUUgp9lUHP52GawCAZKRbKYybcQNyoHX92otiqY2et4KPGcpDWN7rK8H5tzFdcFqmI_EEiE3M0ikprjVU0lK5j4XYBob0s2NdIpsWHoHPaHSXEFcFNEFkD6olAXTutnOYYHrx0-DLq_s--JKW1z64Cx4bkIGDIIQO-9foeysTd91iCtLrZ4nFL9_6x_D-9tqV-T21RAK8remDy4T4psBgENj8cTTxCEdg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2220145722'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idFromToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = {\"cora√ß√£o\": 1, \"amor\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cora√ß√£o': 1, 'amor': 2}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "#consumer_key = 'gorWv93T67QOR10hzCHM1hrge'\n",
    "#consumer_secret = 'NX2ML7n6m7iOLnWNIPz8ivOsbPxoeTl0nwINlRGA7IYNJQkrJk'\n",
    "#access_token = '2220145722-NrzYHGRlYTiHxyPLao0xh47wBbv6p3rtKBC4wOB'\n",
    "#access_token_secret = 'elpVLvQ8RtETJpOyDUqavbUgtHltQ8FwSkwsNfcCQe1Ix'\n",
    "\n",
    "consumer_key = 'JkfuUkynd4WfxXLbSukFok7qJ'\n",
    "consumer_secret = 'fauEtTf9t7aLBY2oweFUgCkhOt54lPH51tJXsmCWFSQGSIVM3S'\n",
    "access_token = '2220145722-DJdBkFQCG07MWyah4266r4uYh5dr4ocuboVAtLt'\n",
    "access_token_secret = 'v8LEbhnVgRNLqkD5FNSJ2d0227iHuObcIJILzO26snGry'\n",
    "\n",
    "#consumer_key = 'YOG262i3Ssnaj8dnnwfktBVfk'\n",
    "#consumer_secret = 'lgt07aZnqLtnD897CdUF6mZpS6woxnoRtWUvKHO5QEqOAcgndB'\n",
    "#access_token = '2220145722-LrRlWqeBHHz1apgB7EapmmoBadzOJxfapZWBe6Z'\n",
    "#access_token_secret = 'R5wJL5JvrTlgjvtkR8uicmUydNdBGQDUjT6DjUCNQ8cbG'\n",
    "\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ID of the user is : 2220145722\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Prontinho, voc√™ j√° deve conseguir ver o resultado no site agora, qualquer d√∫vida √© s√≥ me chamar http://retrospective-twitter.firebaseapp.com/\n",
    "\n",
    "1329429989717106692, 1330983799124074503, 1069999121984049153, 2743519257, 1293427357, 1057087844345397248, 1027277015966265345, 3483219197\n",
    "\n",
    "huivhs\n",
    "GAHYOOHY\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "screen_name = \"caiqueocoelho\"\n",
    "  \n",
    "# fetching the user \n",
    "user = api.get_user(screen_name) \n",
    "  \n",
    "# fetching the ID \n",
    "ID = user.id_str \n",
    "  \n",
    "print(\"The ID of the user is : \" + ID) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(screen_name):\n",
    "        startDate = datetime.datetime(2020, 1, 1, 0, 0, 0)\n",
    "        tweets = []\n",
    "        tweets_created_at = []\n",
    "        tweets_user_mentions_id = []\n",
    "        tweet_user_mentions_name = []\n",
    "        favorite_count = {}\n",
    "        retweet_count = {}\n",
    "        \n",
    "        try:\n",
    "            for tweet in tweepy.Cursor(api.user_timeline, screen_name=screen_name, include_rts=False, tweet_mode = 'extended').items():\n",
    "                if tweet.created_at > startDate:\n",
    "                    tweet = json.dumps(tweet._json)\n",
    "                    tweet = json.loads(tweet)\n",
    "                    tweets_created_at.append(tweet['created_at'])\n",
    "                    tweets.append(tweet['full_text'].replace('\\n', ' '))\n",
    "                    favorite_count[tweet['id_str']] = (tweet['favorite_count'], tweet['full_text'])\n",
    "                    retweet_count[tweet['id_str']] = (tweet['retweet_count'], tweet['full_text'])\n",
    "                    for user in tweet['entities']['user_mentions']:\n",
    "                        tweets_user_mentions_id.append(user['id_str'])\n",
    "                        tweet_user_mentions_name.append(user['name'])\n",
    "                else:\n",
    "                    break\n",
    "            return tweets, tweets_created_at, tweets_user_mentions_id, tweet_user_mentions_name, favorite_count, retweet_count\n",
    "        except Exception as e:\n",
    "            print(\"Error : \" + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets, tweets_created_at, tweets_user_mentions_id, tweet_user_mentions_name, favorite_count, retweet_count = get_tweets(screen_name = 'caiqueocoelho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2309"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def give_emoji_free_text(text):\n",
    "        allchars = [str for str in text]\n",
    "        emoji_list = [c for c in allchars if c in emoji.UNICODE_EMOJI]\n",
    "        clean_text = ' '.join(\n",
    "            [str for str in text.split() if not any(i in str for i in emoji_list)])\n",
    "\n",
    "        return clean_text\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "\n",
    "        text = ' '.join(\n",
    "            re.sub(\"(@[A-Za-z0-9]+)\", \" \", tweet).split())\n",
    "\n",
    "        '''\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U0001F1F2-\\U0001F1F4\"  # Macau flag\n",
    "        u\"\\U0001F1E6-\\U0001F1FF\"  # flags\n",
    "        u\"\\U0001F600-\\U0001F64F\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U0001F1F2\"\n",
    "        u\"\\U0001F1F4\"\n",
    "        u\"\\U0001F620\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u2640-\\u2642\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "\n",
    "        text = emoji_pattern.sub(r'', text)\n",
    "        '''\n",
    "\n",
    "        text = give_emoji_free_text(text)\n",
    "        \n",
    "        text = re.sub(r'http\\S+', '', text)\n",
    "        text = re.sub(r'www\\S+', '', text)\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['@retrott2020 o meu n√£o t√° indo, diz que deu erro https://www.globo.com/ www.globo.com/ http://www.globo.com/',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "new_tweets = []\n",
    "for item in tweets:\n",
    "    new_tweets.append(clean_tweet(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('caique_new_tweets.txt', 'w') as f:\n",
    "    for item in new_tweets:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fri Jan 01 02:24:08 +0000 2021'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_created_at[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saber que ele tbm sente nossa falta √© o que me faz dia ap√≥s dia amar mais o bae. ele trabalha tanto, da tudo de si e um pouco mais por n√≥s... √©, eu realmente amo ele',\n",
       " 'ele viu que est√°vamos sentindo sua falta, isso me deixou t√£o triste :( foque no seu trabalho pequeno, estaremos te esperando :( https://t.co/O1n1KMtlRR',\n",
       " 'cu',\n",
       " '@olderksm https://t.co/9OCFIB4C7t',\n",
       " '@retrott2020 o meu n√£o t√° indo, diz que deu erro',\n",
       " '@baebaejins algo tipo assim https://t.co/G2LXFky6aj',\n",
       " 'https://t.co/XLsKZdjoF0',\n",
       " '@baebaejins n√£o acredito vei n√£o vale isso',\n",
       " 'GENTE COMO ASSIM? A DEB √â BOIOLA VCS EST√ÉO ENGANADOS https://t.co/o7ihcEEcD2',\n",
       " '@baebaejins s√≥ errou o 1',\n",
       " '@BY0UNGGIRL 2$C?',\n",
       " '@baebaejins chutei o ! pq o cedrico √© lindo e combina com vc',\n",
       " '@baebaejins no m√≠nimo o 4 pq o resto eu chutei',\n",
       " '@baebaejins 4#E!',\n",
       " 'cix plmds seus f√£s est√£o entrando em um colapso mental aparece logo pra entreter essa gente',\n",
       " '@BY0UNGGIRL 16/03 üòî',\n",
       " '@cixpallet SUN PELO AMOR DE DEUSKKKKKKKKKKKK',\n",
       " 'https://t.co/dHw4wSo42I',\n",
       " 'marca√ß√µes; @i4goni @starlightgoni @hyuck__voice @seunghunlips @oswsun95 @peekgi @baebaejins @cixpallet @wonycix',\n",
       " 'cix comeback em fevereiro se preparem para os patr√µes voltando com mais uma saga impec√°vel de mv, conceitos e teorias incr√≠veis ! @CIX_Official #CIX #Ïî®ÏïÑÏù¥ÏóëÏä§  https://t.co/wvz5vbNNqJ',\n",
       " 'n√£o sei se eu tento entender o que houve aqui ou se tento parar de rir @CIX_Official #CIX #Ïî®ÏïÑÏù¥ÏóëÏä§ https://t.co/7NhsgTaK85',\n",
       " '@CIX_Official #CIX #Ïî®ÏïÑÏù¥ÏóëÏä§ https://t.co/4txKT11cbw',\n",
       " '@CIX_Official #CIX #Ïî®ÏïÑÏù¥ÏóëÏä§ https://t.co/A5DnuQPPdC',\n",
       " '@CIX_Official #CIX #Ïî®ÏïÑÏù¥ÏóëÏä§ https://t.co/SRfeuWUPMt',\n",
       " 'o baejin comeu....... @CIX_Official #CIX #Ïî®ÏïÑÏù¥ÏóëÏä§ https://t.co/jo3ikrkDdF',\n",
       " '@CIX_Official #CIX #Ïî®ÏïÑÏù¥ÏóëÏä§ https://t.co/ZpM4nlzXn2',\n",
       " '@CIX_Official #CIX #Ïî®ÏïÑÏù¥ÏóëÏä§ https://t.co/WgsaHyfi8n',\n",
       " '@CIX_Official #CIX #Ïî®ÏïÑÏù¥ÏóëÏä§  https://t.co/gstO4mdqQW',\n",
       " '@CIX_Official #CIX #Ïî®ÏïÑÏù¥ÏóëÏä§ https://t.co/kBtLdGkQyo',\n",
       " '@CIX_Official #CIX #Ïî®ÏïÑÏù¥ÏóëÏä§  https://t.co/HJNAPOQ7z7',\n",
       " 'esse aqui serio...... @CIX_Official #CIX #Ïî®ÏïÑÏù¥ÏóëÏä§ https://t.co/AFUQt145oY',\n",
       " '@CIX_Official #CIX #Ïî®ÏïÑÏù¥ÏóëÏä§ https://t.co/umH32g6yC1',\n",
       " '@CIX_Official #CIX #Ïî®ÏïÑÏù¥ÏóëÏä§ https://t.co/usn7kCpbYs',\n",
       " '@CIX_Official #CIX #Ïî®ÏïÑÏù¥ÏóëÏä§  https://t.co/7TjrcKovjh',\n",
       " '@CIX_Official #CIX #Ïî®ÏïÑÏù¥ÏóëÏä§ https://t.co/nQHkzJ8clp',\n",
       " 'momentos do cix que ningu√©m sabe explicar; a thread @CIX_Official #CIX #Ïî®ÏïÑÏù¥ÏóëÏä§ https://t.co/DYTNw3anQ3',\n",
       " '@wonycix pode deixar',\n",
       " '@baebaejins indo marcar',\n",
       " '@jwoodior marco, pode deixar',\n",
       " '@oswsun95 marco sim !',\n",
       " '@peekgi marco sim amor',\n",
       " 'a plantinha na logo nossa que coisa mais linda o universe t√° da parab√©ns @CIX_Official #CIX #Ïî®ÏïÑÏù¥ÏóëÏä§ https://t.co/v5wLlY2zCL',\n",
       " '@seunghunlips po deixar',\n",
       " '@i4goni marco vida',\n",
       " '@starlightgoni marcoo',\n",
       " '@hyuck__voice marco',\n",
       " '@starlightgoni o meu √© sonserina pq apertei em uma resposta sem querer e nunca refiz',\n",
       " 'vem a√≠ üëÄ https://t.co/eJTYoG7DSo',\n",
       " '@fromhunie calma amg calma vai dar tudo certo',\n",
       " '@fromhunie corta aqui agora üëâüèºüëàüèª',\n",
       " 'MDSSSSS AHWGAHQFHWIEIEJEJHEHRHRHEJDIDHDBEB üò≠üò≠üò≠üò≠üò≠ https://t.co/aBinpHWPI2',\n",
       " '@Iuvschs oi vida bem vindo! sinta-se √† vontade pra interagir cmg ok? qualquer coisa t√¥ disposta a te ajudar ‚ô°',\n",
       " '@orinieIk √© bom sofrer com outras pessoas',\n",
       " '@tullipsruto bolsonaro que lute pq eu vou tirar ele do poder',\n",
       " '@tullipsruto amo vcs üíñ',\n",
       " '@tullipsruto üò©',\n",
       " '@tullipsruto a elei√ß√£o vai ser amanh√£',\n",
       " 'a cami e a minnie, eu sou a que mais me meto em briga https://t.co/KnVKZ0ng5K',\n",
       " 'coreanos que dan√ßam https://t.co/Jsb40qz5iq',\n",
       " 'n√≥s 3 https://t.co/7WpjtWctC3',\n",
       " 'eu com certeza, mas n√≥s 3 defenderiamos nos 3 https://t.co/tEcU9VagRX',\n",
       " 'a jasmine e a cami https://t.co/1TOvyvVFbo',\n",
       " 'dizem que sou eu mas n√£o acho https://t.co/NnlmIedimA',\n",
       " 'a minnie tava de olho no wonwoo do svt, a√≠ a cami tava mandando foto dele pra ela e fiz o mesmo. (eu e a cami n√£o nos conhec√≠amos) da√≠ eu criei um grupo com as duas pra minnie assumir ele. a√≠ a gente transformou esse grupo no squad üíÖüèª https://t.co/AxhXP3HTBv',\n",
       " 'acho que eu?? n√£o sei https://t.co/tmqIx3DzIE',\n",
       " 'a minnie https://t.co/qUAPXKasoz',\n",
       " 'eu n√£o sei?.?? https://t.co/iVmUcdyDus',\n",
       " 'minnie protagonista, eu e cami antagonista https://t.co/SSmpXRIvTT',\n",
       " 'eu n√£o sei nem a minha, imagine a delas https://t.co/mNbhWUgDOd',\n",
       " 'acho que nenhuma https://t.co/Qenj70N8Ni',\n",
       " 'a gente n√£o definiu mas eu que organizo as reuni√µes do grupo https://t.co/QlcvRSpXkA',\n",
       " 'n√≥s 3 https://t.co/bu7LKCZspL',\n",
       " 'a cami https://t.co/DA9a3GiJIr',\n",
       " 'acho que todas n√≥skkkkk https://t.co/tQi1LWimQE',\n",
       " 'a minnie https://t.co/TJxiMl8ZhI',\n",
       " 'vou fazer com o cacatuas, a @tullipsruto e @perfectjyunhao https://t.co/9hU2xSyL4h',\n",
       " '@baebaejins da onde que eu sou famosa',\n",
       " '@seunghunfix ella vc tem mt bom gosto',\n",
       " 'j√° sinto que vou passar raiva com fix hoje https://t.co/Gc3HzBsyHW',\n",
       " '@lipsbae o baejin e o minhyun MDSJJSBDVGERV üò©üò©üò©üò©üò©üò©üò©üò©üò©üò©üò©üò©üò©üò© EU VOU CHORAR',\n",
       " '@Frigga0 doyoung do nct',\n",
       " 'mbti n√£o serve pra porra nenhuma. se vc justifica sua personalidade por causa disso, fique longe de mim vai acreditar nisso na puta que pariu √© igual signo eu hein',\n",
       " '@baejincelestial @lipsbae @baebaejins @G0THICSUK NAO JULY NAO APAGA ISSO AGORA VC ACHA QUR D3PRESSAO √â BRINCADEIRA VC ACHA √â EU TE PROCESSO',\n",
       " 'baejin desculpa se eu tiver te atrapalhando,  se vc estiver descansando mas avisa que t√° bem por favor eu acordo j√° pensando se vc t√° bem e vc continua sumido e isso me deixa preocupada üòî @CIX_Official',\n",
       " 'baejin onde vc t√° tem internet?',\n",
       " 'baejin onde vc t√° @CIX_Official baejin onde vc t√° @CIX_Official baejin onde vc t√° @CIX_Official baejin onde vc t√° @CIX_Official baejin onde vc t√° @CIX_Official baejin onde vc t√° @CIX_Official baejin onde vc t√° @CIX_Official baejin onde vc t√° @CIX_Official baejin onde vc t√°',\n",
       " 'eles ü•∫ü•∫ü•∫ü•∫ü•∫ü•∫ü•∫ü•∫ü•∫ü•∫ü•∫ü•∫ü•∫ https://t.co/v64JEJ4cS5']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thu Jan 07 19:30:51 +0000 2021'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_created_at[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatDateArray(dates):\n",
    "    datesFormated = []\n",
    "    for date in dates:\n",
    "        dateSplitted = date.split('-')\n",
    "        dateFormated = dateSplitted[1]\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Dec', '12')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Nov', '11')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Oct', '10')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Sep', '09')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Agp', '08')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Jul', '07')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Jun', '06')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('May', '05')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Apr', '04')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Mar', '03')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Feb', '02')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Jan', '01')\n",
    "        dateFormated += '-' + dateSplitted[0] + '-' + dateSplitted[2]\n",
    "        datesFormated.append(dateFormated)\n",
    "\n",
    "    return datesFormated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertDate(tweet_dates):\n",
    "    dates = []\n",
    "    for date in tweet_dates:\n",
    "        dateSplitted = date.split(' ')\n",
    "        date = dateSplitted[1] + '-' + dateSplitted[2] + '-' + dateSplitted[-1]\n",
    "        dates.append(date)\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "convertedDateTweets = convertDate(tweets_created_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "convertedDateTweetsFormatted = formatDateArray(convertedDateTweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '11-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '10-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '09-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '08-01-2021',\n",
       " '07-01-2021',\n",
       " '07-01-2021',\n",
       " '07-01-2021',\n",
       " '07-01-2021',\n",
       " '07-01-2021',\n",
       " '07-01-2021',\n",
       " '07-01-2021',\n",
       " '07-01-2021',\n",
       " '07-01-2021',\n",
       " '07-01-2021',\n",
       " '07-01-2021',\n",
       " '07-01-2021',\n",
       " '07-01-2021',\n",
       " '07-01-2021',\n",
       " '07-01-2021',\n",
       " '07-01-2021']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertedDateTweetsFormatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMaxValueInTuple(tweets):\n",
    "    maxValue = 0\n",
    "    maxTweet = None\n",
    "    for key, value in tweets.items():\n",
    "        if value[0] > maxValue:\n",
    "            maxValue = value[0]\n",
    "            maxTweet = value[1]\n",
    "            \n",
    "    return maxTweet, maxValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('@eliseuneto üó£Ô∏è O berro que eu dei. Perd√£o Eliseu, achei que fosse o Cabe√ß√£o de malha√ß√£o @sergiohondja corre aqui https://t.co/or94FCws76', 49)\n"
     ]
    }
   ],
   "source": [
    "print(getMaxValueInTuple(favorite_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Corinthians ü§ù Taylor Swift https://t.co/ckrtewaXOq', 1)\n"
     ]
    }
   ],
   "source": [
    "print(getMaxValueInTuple(retweet_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thu Dec 24 02:31:40 +0000 2020',\n",
       " 'Wed Dec 23 23:16:19 +0000 2020',\n",
       " 'Wed Dec 23 23:10:10 +0000 2020',\n",
       " 'Wed Dec 23 23:05:08 +0000 2020',\n",
       " 'Wed Dec 23 23:03:18 +0000 2020',\n",
       " 'Wed Dec 23 23:02:34 +0000 2020',\n",
       " 'Wed Dec 23 15:52:35 +0000 2020',\n",
       " 'Wed Dec 23 15:49:29 +0000 2020',\n",
       " 'Mon Dec 21 21:27:53 +0000 2020',\n",
       " 'Mon Dec 21 19:22:45 +0000 2020',\n",
       " 'Mon Dec 21 19:00:41 +0000 2020',\n",
       " 'Mon Dec 21 18:53:54 +0000 2020',\n",
       " 'Mon Dec 21 17:30:43 +0000 2020',\n",
       " 'Mon Dec 21 16:47:19 +0000 2020',\n",
       " 'Mon Dec 21 16:19:58 +0000 2020',\n",
       " 'Mon Dec 21 16:19:57 +0000 2020',\n",
       " 'Sun Dec 20 22:03:16 +0000 2020',\n",
       " 'Sat Dec 19 02:41:05 +0000 2020',\n",
       " 'Thu Dec 17 23:06:15 +0000 2020',\n",
       " 'Thu Dec 17 22:18:00 +0000 2020']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_created_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to de f√©rias favor n√£o falar comigo at√© ano q vem',\n",
       " 'to de f√©rias favor n√£o falar comigo at√© ano q vem',\n",
       " 'casey/',\n",
       " 'bia b',\n",
       " 'Camila Corsini',\n",
       " 'Fiel News',\n",
       " 'Paulo Coelho',\n",
       " 'Isabella Bicalho Frazeto',\n",
       " 'Eliseu Neto',\n",
       " 'Serginho Hondjakoff',\n",
       " 'xulliane ‚ú®',\n",
       " 'uhala',\n",
       " 'Mary üå∏',\n",
       " 'Lucas Paulon',\n",
       " 'motivos pelos quais o mundo est√° acabando',\n",
       " 'Eduardo Quagliato',\n",
       " 'Marie Drake',\n",
       " 'Marie Drake']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_user_mentions_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@chorumes Por nada, espero que goste'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thu Dec 24 02:31:40 +0000 2020'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_created_at[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "def maxInteraction(tweets):\n",
    "    arrobas = {}\n",
    "    for tweet in tweets:\n",
    "        for word in tweet.split(' '):\n",
    "            word = word.lower()\n",
    "            word = word.replace(':', '')\n",
    "            if('@' in word):\n",
    "                if(word in arrobas):\n",
    "                    arrobas[word] = arrobas[word] + 1\n",
    "                else:\n",
    "                    arrobas[word] = 1\n",
    "          \n",
    "    return arrobas, sorted(arrobas.items(), key=operator.itemgetter(1), reverse=True), max(arrobas.items(), key=operator.itemgetter(1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrobasDict, arrobasOrdered, maxArroba = maxInteraction(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('@chorumes', 2),\n",
       " ('@mcruzdrake', 2),\n",
       " ('@caseykcaruso', 1),\n",
       " ('@ogaiob', 1),\n",
       " ('@camilalcorsini', 1),\n",
       " ('@fielnews', 1),\n",
       " ('@paulocoelho', 1),\n",
       " ('@bisnotforbella', 1),\n",
       " ('@eliseuneto', 1),\n",
       " ('@sergiohondja', 1),\n",
       " ('@jualberigi', 1),\n",
       " ('@uhala', 1),\n",
       " ('@mavictor_', 1),\n",
       " ('@lucaspaulon_', 1),\n",
       " ('@fimdelworld', 1),\n",
       " ('@quagliato', 1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrobasOrdered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@chorumes'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxArroba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrobasDict[maxArroba]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def firtTwitterYear(tweets):\n",
    "    return tweets[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@mcruzdrake Me all days in daily meeting'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firtTwitterYear(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thu Dec 17 22:18:00 +0000 2020'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_created_at[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2436\n",
    "len(tweets_created_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertDate(tweet_dates):\n",
    "    dates = []\n",
    "    for date in tweet_dates:\n",
    "        dateSplitted = date.split(' ')\n",
    "        date = dateSplitted[1] + '-' + dateSplitted[2] + '-' + dateSplitted[-1]\n",
    "        dates.append(date)\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "convertedDateTweets = convertDate(tweets_created_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dec-24-2020',\n",
       " 'Dec-23-2020',\n",
       " 'Dec-23-2020',\n",
       " 'Dec-23-2020',\n",
       " 'Dec-23-2020',\n",
       " 'Dec-23-2020',\n",
       " 'Dec-23-2020',\n",
       " 'Dec-23-2020',\n",
       " 'Dec-21-2020',\n",
       " 'Dec-21-2020',\n",
       " 'Dec-21-2020',\n",
       " 'Dec-21-2020',\n",
       " 'Dec-21-2020',\n",
       " 'Dec-21-2020',\n",
       " 'Dec-21-2020',\n",
       " 'Dec-21-2020',\n",
       " 'Dec-20-2020',\n",
       " 'Dec-19-2020',\n",
       " 'Dec-17-2020',\n",
       " 'Dec-17-2020']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertedDateTweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatDateArray(dates):\n",
    "    datesFormated = []\n",
    "    for date in dates:\n",
    "        dateSplitted = date.split('-')\n",
    "        dateFormated = dateSplitted[1]\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Dec', '12')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Nov', '11')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Oct', '10')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Sep', '09')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Agp', '08')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Jul', '07')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Jun', '06')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('May', '05')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Apr', '04')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Mar', '03')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Feb', '02')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Jan', '01')\n",
    "        dateFormated += '-' + dateSplitted[0] + '-' + dateSplitted[2]\n",
    "        datesFormated.append(dateFormated)\n",
    "        \n",
    "    return datesFormated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['24-12-2020', '23-12-2020', '23-12-2020', '23-12-2020', '23-12-2020', '23-12-2020', '23-12-2020', '23-12-2020', '21-12-2020', '21-12-2020', '21-12-2020', '21-12-2020', '21-12-2020', '21-12-2020', '21-12-2020', '21-12-2020', '20-12-2020', '19-12-2020', '17-12-2020', '17-12-2020']\n"
     ]
    }
   ],
   "source": [
    "print(formatDateArray(convertedDateTweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dayWithMax(tweets):\n",
    "    dates = {}\n",
    "    for date in tweets:\n",
    "        if date in dates:\n",
    "            dates[date] = dates[date] + 1\n",
    "        else:\n",
    "            dates[date] = 1\n",
    "    #return dates, max(dates.items(), key=operator.itemgetter(1))[0]\n",
    "    return dates, sorted(dates.items(), key=operator.itemgetter(1), reverse=True), max(dates.items(), key=operator.itemgetter(1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "datesDictTweet, datesOrderedTweet, maxDateTweet = dayWithMax(convertedDateTweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dec-21-2020'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxDateTweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datesDictTweet[maxDateTweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dec-21-2020', 8),\n",
       " ('Dec-23-2020', 7),\n",
       " ('Dec-17-2020', 2),\n",
       " ('Dec-24-2020', 1),\n",
       " ('Dec-20-2020', 1),\n",
       " ('Dec-19-2020', 1)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datesOrderedTweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatDateConverted(dates):\n",
    "    datesFormated = []\n",
    "    for date in dates:\n",
    "        dateSplitted = date[0].split('-')\n",
    "        dateFormated = dateSplitted[1]\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Dec', '12')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Nov', '11')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Oct', '10')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Sep', '09')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Agp', '08')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Jul', '07')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Jun', '06')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('May', '05')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Apr', '04')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Mar', '03')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Feb', '02')\n",
    "        dateSplitted[0] = dateSplitted[0].replace('Jan', '01')\n",
    "        dateFormated += '-' + dateSplitted[0] + '-' + dateSplitted[2]\n",
    "        datesFormated.append(dateFormated)\n",
    "        \n",
    "    return datesFormated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "datesFormated = formatDateConverted(datesOrderedTweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['21-12-2020', '23-12-2020', '17-12-2020', '24-12-2020', '20-12-2020', '19-12-2020']\n"
     ]
    }
   ],
   "source": [
    "print(datesFormated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def totalTweets(tweets):\n",
    "    return len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxWord(tweets):\n",
    "    words = {}\n",
    "    for tweet in tweets:\n",
    "        for word in tweet.split(' '):\n",
    "            word = word.lower()\n",
    "            if word not in stop_words and '@' not in word:\n",
    "                if(word in words):\n",
    "                    words[word] = words[word] + 1\n",
    "                else:\n",
    "                    words[word] = 1\n",
    "    \n",
    "    return words, sorted(words.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, orderedWords = maxWord(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#corinthians', 5),\n",
       " ('code', 5),\n",
       " ('open', 4),\n",
       " ('pudim', 4),\n",
       " ('deus', 4),\n",
       " ('stories', 4),\n",
       " ('hahahahahahahahaha', 3),\n",
       " ('morto', 3),\n",
       " ('android', 3),\n",
       " ('vale', 3)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orderedWords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Liked\n",
    "User = \"@caiqueocoelho\"\n",
    "tweetsLikedAuthorScreenName = []\n",
    "tweetsLikedAuthorName = []\n",
    "tweetsLikedDay = []\n",
    "# Cursor is the search method this search query will return 20 of the users latest favourites just like the php api you referenced\n",
    "for favorite in tweepy.Cursor(api.favorites, id=User).items(20):\n",
    "    # To get diffrent data from the tweet do \"favourite\" followed by the information you want the response is the same as the api you refrenced too\n",
    "    tweet = json.dumps(favorite._json)\n",
    "    tweet = json.loads(tweet)\n",
    "    tweetsLikedAuthorScreenName.append(tweet['user']['screen_name'])\n",
    "    tweetsLikedAuthorName.append(tweet['user']['name'])\n",
    "    tweetsLikedDay.append(tweet['created_at'])\n",
    "    \n",
    "    #print(tweet)\n",
    "    #Basic information about the user who created the tweet that was favorited\n",
    "    #print(favorite)\n",
    "    #print('Tweet Author:')\n",
    "    # Print the screen name of the tweets auther\n",
    "    #print('Screen Name: '+str(favorite.user.screen_name.encode(\"utf-8\")))\n",
    "    #print('Name: '+str(favorite.user.name.encode(\"utf-8\")))\n",
    "\n",
    "\n",
    "    #Basic information about the tweet that was favorited\n",
    "    #print('\\nTweet:')\n",
    "    # Print the id of the tweet the user favorited\n",
    "    #print('Tweet Id: '+str(favorite.id))\n",
    "    # Print the text of the tweet the user favorited\n",
    "    #print('Tweet Text: '+str(favorite.text.encode(\"utf-8\")))\n",
    "    # Encoding in utf-8 is a good practice when using data from twitter that users can submit (it avoids the program crashing because it can not encode characters like emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EmmaBostian',\n",
       " '_judemood',\n",
       " 'notariinea',\n",
       " 'riansantullo',\n",
       " 'MarceloAdnet',\n",
       " 'ogaiob',\n",
       " 'B_Manfredini',\n",
       " 'melindagates',\n",
       " 'EmmaBostian',\n",
       " 'MariahCarey']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsLikedAuthorScreenName[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-09b02c97891a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfavorites\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2220145722'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;31m# Reached end of current page, get the next page...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRawParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__self__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tweepy/binder.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tweepy/binder.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    161\u001b[0m                                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_on_rate_limit_notify\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                                         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rate limit reached. Sleeping for: %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msleep_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m                                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msleep_time\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# sleep for few extra sec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0;31m# if self.wait_on_rate_limit and self._reset_time is not None and \\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for a in tweepy.Cursor(api.favorites, id='2220145722').items(20):\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMax(tweets):\n",
    "    dictArray = {}\n",
    "    for tweet in tweets:\n",
    "        if tweet in dictArray:\n",
    "            dictArray[tweet] += 1\n",
    "        else:\n",
    "            dictArray[tweet] = 1\n",
    "    return dictArray, sorted(dictArray.items(), key=operator.itemgetter(1), reverse=True), max(dictArray.items(), key=operator.itemgetter(1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "authorsLiked, authorsLikedOrdered, maxLikedAuthor = getMax(tweetsLikedAuthorScreenName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lucaspaulon_'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxLikedAuthor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "authorsLikedName, authorsLikedOrderedName, maxLikedAuthorName = getMax(tweetsLikedAuthorName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lucas Paulon'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxLikedAuthorName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dec-20-2020'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertedDateLikeds = convertDate(tweetsLikedDay)\n",
    "datesDictLikeds, datesOrderedLikeds, maxDateTweetLikeds = dayWithMax(convertedDateLikeds)\n",
    "maxDateTweetLikeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datesDictLikeds[maxDateTweetLikeds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dec-09-2020', 7), ('Dec-05-2020', 6), ('Nov-05-2020', 6)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datesOrderedLikeds[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweetsDate = []\n",
    "retweets = []\n",
    "def get_retweets(screen_name, count, tweet_mode, include_entities, truncated, data_since):\n",
    "        try:\n",
    "            for tweet in tweepy.Cursor(api.user_timeline, screen_name=screen_name, q='filter:retweets', tweet_mode = 'extended', data_since='2020-01-01').items(10):\n",
    "                tweet = json.dumps(tweet._json)\n",
    "                tweet = json.loads(tweet)\n",
    "                if('RT' in tweet['full_text'].split(' ')[0]):\n",
    "                    retweetsDate.append(tweet['created_at'])\n",
    "                    retweets.append(tweet['full_text'].replace('\\n', ' '))\n",
    "        except Exception as e:\n",
    "            # print error (if any)\n",
    "            print(\"Error : \" + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retweets(screen_name = 'theanobrain', count = 10, tweet_mode='extended', include_entities=True, truncated=False, data_since='2019-11-28')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT @vcguedes_14: A vida de um infp todos os dias https://t.co/6XXXDRtkhN',\n",
       " 'RT @mulheresefrases: https://t.co/R1YgNF8WbQ']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScreenNameRT(retweets):\n",
    "    authors = []\n",
    "    for tweet in retweets:\n",
    "        tweet = tweet.split(' ')\n",
    "        if len(tweet) > 0:\n",
    "          authors.append(tweet[1].replace(':', ''))\n",
    "    return authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@vcguedes_14', '@mulheresefrases']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getScreenNameRT(retweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweetsAuthorScreenName = []\n",
    "def getScreenNameRT(retweets):\n",
    "    authors = []\n",
    "    for tweet in retweets:\n",
    "        print(tweet)\n",
    "        tweet = tweet.split(' ')\n",
    "        authors.append(tweet[1].replace(':', ''))\n",
    "    return authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @AndreiaSadi: Td os dias os relatos tristes, de partir o üíî, das fam√≠lias de v√≠timas da Covid. N√£o s√£o n√∫meros. S√£o hist√≥rias, amor, saud‚Ä¶\n",
      "RT @gduvivier: Nicette gigante e eterna! ‚ù§Ô∏è https://t.co/fiCpgBvpbS\n",
      "RT @tamylemos: Odeio escrever mas 2020 me fez soltar isso a√≠ √≥: https://t.co/0SrUzt96J6\n",
      "RT @malupr: O Rubinho pode at√© ser vacinado primeiro, mas o importante √© a vacina√ß√£o em Massa https://t.co/TusOC1rkuP\n",
      "RT @whoisgeovanna: acabei de ver a m√£e de uma crian√ßa chamando o filho de bolsonaro pq ele n√£o queria usar a m√°scara kkkkkkkkkkkk\n"
     ]
    }
   ],
   "source": [
    "retweetsAuthorScreenName = getScreenNameRT(retweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrobasRtDict, arrobasRtOrdered, maxRTName = getMax(retweetsAuthorScreenName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('@AndreiaSadi', 1),\n",
       " ('@gduvivier', 1),\n",
       " ('@tamylemos', 1),\n",
       " ('@malupr', 1),\n",
       " ('@whoisgeovanna', 1)]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrobasRtOrdered[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HAHAHAHAHAHAHAHAHA',\n",
       " '@AndreiaSadi',\n",
       " '@gduvivier',\n",
       " '@tamylemos',\n",
       " '@malupr',\n",
       " '@whoisgeovanna']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retweetsAuthorScreenName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sat Dec 19 01:40:19 +0000 2020'"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertedDateLikeds = convertDate(tweetsLikedDay)\n",
    "datesDictRetweets, datesOrderedRetweets, maxDateRetweets = dayWithMax(retweetsDate)\n",
    "maxDateRetweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sat Dec 19 01:40:19 +0000 2020', 1),\n",
       " ('Fri Dec 18 17:16:32 +0000 2020', 1),\n",
       " ('Fri Dec 18 04:45:59 +0000 2020', 1)]"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datesOrderedRetweets[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.8/concurrent/futures/__init__.py:49: RuntimeWarning: coroutine 'Twint.main' was never awaited\n",
      "  from .thread import ThreadPoolExecutor as te\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 1.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 8.0 secs\n"
     ]
    }
   ],
   "source": [
    "import twint\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Configure\n",
    "c = twint.Config()\n",
    "c.Username = \"caiqueocoelho\"\n",
    "c.Search = \"project\"\n",
    "\n",
    "# Run\n",
    "twint.run.Search(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
